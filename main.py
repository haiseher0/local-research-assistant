import os
import sys
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_community.chat_models import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser

# –≠—Ç–æ—Ç –∫–æ–¥ –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ—Ç langchain.chains, –ø–æ—ç—Ç–æ–º—É –æ—à–∏–±–∫–∞ –∏—Å—á–µ–∑–Ω–µ—Ç
class ResearchRAG:
    def __init__(self, pdf_path: str):
        self.pdf_path = pdf_path
        print("Initializing models...")
        self.embeddings = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
        self.llm = ChatOllama(model="llama3", temperature=0)
        self.vector_store = None

    def ingest(self):
        if not os.path.exists(self.pdf_path):
            print(f"ERROR: File {self.pdf_path} not found!")
            return

        print(f"Loading {self.pdf_path}...")
        loader = PyPDFLoader(self.pdf_path)
        docs = loader.load()

        print("Splitting text...")
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        splits = text_splitter.split_documents(docs)
        
        print("Building vector database...")
        self.vector_store = FAISS.from_documents(splits, self.embeddings)
        print("Done.")

    def query(self, question: str):
        if not self.vector_store:
            return "Error: Run ingest() first!"

        print(f"\nThinking on: {question}...")
        
        # 1. Retriever (–ò—Å–∫–∞—Ç–µ–ª—å)
        retriever = self.vector_store.as_retriever(search_kwargs={"k": 3})
        
        # 2. Template (–®–∞–±–ª–æ–Ω –∑–∞–ø—Ä–æ—Å–∞)
        template = """Answer the question based only on the following context:
        {context}

        Question: {question}
        """
        prompt = ChatPromptTemplate.from_template(template)

        # 3. –§—É–Ω–∫—Ü–∏—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        def format_docs(docs):
            return "\n\n".join([d.page_content for d in docs])

        # 4. –¶–µ–ø–æ—á–∫–∞ (Chain) —Å–æ–±—Ä–∞–Ω–Ω–∞—è –≤—Ä—É—á–Ω—É—é
        rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | self.llm
            | StrOutputParser()
        )

        return rag_chain.invoke(question)

if __name__ == "__main__":
    # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è (–∫–∞–∫ –∏ –±—ã–ª–æ)
    # –£–±–µ–¥–∏—Å—å, —á—Ç–æ paper.pdf –Ω–∞ –º–µ—Å—Ç–µ
    pdf_file = "paper.pdf"
    
    rag = ResearchRAG(pdf_path=pdf_file)
    rag.ingest()

    # 2. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π —Ü–∏–∫–ª
    print("\n" + "="*50)
    print("ü§ñ Research Assistant Ready! (Type 'exit' to quit)")
    print("="*50)

    while True:
        # –ñ–¥–µ–º –≤–≤–æ–¥–∞ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_input = input("\nUser: ")

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –≤—ã—Ö–æ–¥
        if user_input.lower() in ["exit", "quit", "q"]:
            print("Goodbye!")
            break
        
        # –ï—Å–ª–∏ –≤–≤–µ–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
        if not user_input.strip():
            continue

        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤–æ–ø—Ä–æ—Å –≤ RAG
        try:
            print(rag.query(user_input))
        except Exception as e:
            print(f"Error: {e}")
